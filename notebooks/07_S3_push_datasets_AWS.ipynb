{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Upload Specific Datasets and Model to S3\n",
                "\n",
                "This notebook uploads processed datasets and trained models to S3.\n",
                "\n",
                "**Security Note**: Credentials are read from environment variables. Do NOT hardcode keys in this file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ AWS Credentials detected.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import boto3\n",
                "from pathlib import Path\n",
                "from dotenv import load_dotenv\n",
                "from botocore.exceptions import ClientError\n",
                "\n",
                "# Load .env file if it exists\n",
                "load_dotenv()\n",
                "\n",
                "# Check if credentials are available (without printing them)\n",
                "if not os.getenv(\"AWS_ACCESS_KEY_ID\") or not os.getenv(\"AWS_SECRET_ACCESS_KEY\"):\n",
                "    raise EnvironmentError(\"❌ AWS credentials not found. Please set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables.\")\n",
                "\n",
                "print(\"✅ AWS Credentials detected.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---- Config ----\n",
                "bucket = \"housing-ml-artifacts\"   # Updated to unique name to avoid AccessDenied\n",
                "region = os.environ.get(\"AWS_DEFAULT_REGION\", \"us-east-1\") # Use region from env or default to us-east-1\n",
                "\n",
                "# Set project root as parent of the notebooks folder\n",
                "PROJECT_ROOT = Path(\"..\").resolve()\n",
                "local_data_dir = PROJECT_ROOT / \"data\" / \"processed\"\n",
                "local_model_dir = PROJECT_ROOT / \"models\"\n",
                "\n",
                "# Initialize S3 Client\n",
                "s3 = boto3.client(\"s3\", region_name=region)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Bucket 'housing-ml-artifacts' already exists.\n"
                    ]
                }
            ],
            "source": [
                "# ---- Ensure Bucket Exists ----\n",
                "def create_bucket_if_not_exists(bucket_name, region=None):\n",
                "    try:\n",
                "        s3.head_bucket(Bucket=bucket_name)\n",
                "        print(f\"✅ Bucket '{bucket_name}' already exists.\")\n",
                "    except ClientError as e:\n",
                "        error_code = e.response['Error']['Code']\n",
                "        if error_code == '404':\n",
                "            print(f\"⚠️ Bucket '{bucket_name}' not found. Creating...\")\n",
                "            if region is None or region == \"us-east-1\":\n",
                "                s3.create_bucket(Bucket=bucket_name)\n",
                "            else:\n",
                "                s3.create_bucket(\n",
                "                    Bucket=bucket_name,\n",
                "                    CreateBucketConfiguration={'LocationConstraint': region}\n",
                "                )\n",
                "            print(f\"✅ Bucket '{bucket_name}' created successfully.\")\n",
                "        else:\n",
                "             print(f\"❌ Error checking bucket: {e}\")\n",
                "             raise\n",
                "\n",
                "create_bucket_if_not_exists(bucket, region)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---- Helper function ----\n",
                "def upload_file(local_path: Path, s3_key: str):\n",
                "    if not local_path.exists():\n",
                "        print(f\"❌ File not found: {local_path}\")\n",
                "        return\n",
                "    print(f\"⬆️ Uploading {local_path.name} → s3://{bucket}/{s3_key}\")\n",
                "    try:\n",
                "        s3.upload_file(str(local_path), bucket, s3_key)\n",
                "        print(\"   ✅ Upload success\")\n",
                "    except Exception as e:\n",
                "        print(f\"   ❌ Upload failed: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "⬆️ Uploading feature_engineered_holdout.csv → s3://housing-ml-artifacts/processed/feature_engineered_holdout.csv\n",
                        "   ✅ Upload success\n",
                        "⬆️ Uploading cleaning_holdout.csv → s3://housing-ml-artifacts/processed/cleaning_holdout.csv\n",
                        "   ✅ Upload success\n",
                        "⬆️ Uploading feature_engineered_train.csv → s3://housing-ml-artifacts/processed/feature_engineered_train.csv\n",
                        "   ✅ Upload success\n",
                        "⬆️ Uploading xgb_best_model.pkl → s3://housing-ml-artifacts/models/xgb_best_model.pkl\n",
                        "   ✅ Upload success\n"
                    ]
                }
            ],
            "source": [
                "# ---- Upload required datasets ----\n",
                "upload_file(local_data_dir / \"feature_engineered_holdout.csv\", \"processed/feature_engineered_holdout.csv\")\n",
                "upload_file(local_data_dir / \"cleaning_holdout.csv\", \"processed/cleaning_holdout.csv\")\n",
                "upload_file(local_data_dir / \"feature_engineered_train.csv\", \"processed/feature_engineered_train.csv\")\n",
                "\n",
                "# ---- Upload model ----\n",
                "upload_file(local_model_dir / \"xgb_best_model.pkl\", \"models/xgb_best_model.pkl\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (venv)",
            "language": "python",
            "name": "venv"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

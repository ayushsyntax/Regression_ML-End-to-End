{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Data Split\n",
    "\n",
    "## Purpose\n",
    "Load the raw housing dataset and split it by **date** (temporal split) to prevent data leakage.\n",
    "\n",
    "### Why Temporal Split?\n",
    "- Random split causes data leakage with time series data\n",
    "- Future data would leak into training set\n",
    "- Model would appear to perform better than reality\n",
    "\n",
    "### Split Strategy\n",
    "- **Training**: 2012-2019 (used to train the model)\n",
    "- **Evaluation**: 2020-2021 (used for validation and hyperparameter tuning)\n",
    "- **Hold-out**: 2022-2023 (completely untouched until final predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ..\\data\\raw\\untouched_raw_original.csv\n",
      "\n",
      "Dataset shape: 884,092 rows x 39 columns\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path(\"../data/raw\")\n",
    "ORIGINAL_FILE = DATA_DIR / \"untouched_raw_original.csv\"\n",
    "\n",
    "print(f\"Loading data from: {ORIGINAL_FILE}\")\n",
    "df = pd.read_csv(ORIGINAL_FILE)\n",
    "print(f\"\\nDataset shape: {df.shape[0]:,} rows x {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_list_price</th>\n",
       "      <th>median_ppsf</th>\n",
       "      <th>median_list_ppsf</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>pending_sales</th>\n",
       "      <th>new_listings</th>\n",
       "      <th>inventory</th>\n",
       "      <th>median_dom</th>\n",
       "      <th>avg_sale_to_list</th>\n",
       "      <th>sold_above_list</th>\n",
       "      <th>off_market_in_two_weeks</th>\n",
       "      <th>city</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>year</th>\n",
       "      <th>bank</th>\n",
       "      <th>bus</th>\n",
       "      <th>hospital</th>\n",
       "      <th>mall</th>\n",
       "      <th>park</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>school</th>\n",
       "      <th>station</th>\n",
       "      <th>supermarket</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Per Capita Income</th>\n",
       "      <th>Total Families Below Poverty</th>\n",
       "      <th>Total Housing Units</th>\n",
       "      <th>Median Rent</th>\n",
       "      <th>Median Home Value</th>\n",
       "      <th>Total Labor Force</th>\n",
       "      <th>Unemployed Population</th>\n",
       "      <th>Total School Age Population</th>\n",
       "      <th>Total School Enrollment</th>\n",
       "      <th>Median Commute Time</th>\n",
       "      <th>price</th>\n",
       "      <th>city_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>46550.0</td>\n",
       "      <td>217450.0</td>\n",
       "      <td>31.813674</td>\n",
       "      <td>110.183666</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>ATL</td>\n",
       "      <td>30002</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5811.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>33052.0</td>\n",
       "      <td>5811.0</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>279500.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>200773.999557</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>61870.0</td>\n",
       "      <td>245000.0</td>\n",
       "      <td>40.723982</td>\n",
       "      <td>130.528256</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.946642</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>ATL</td>\n",
       "      <td>30002</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5811.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>33052.0</td>\n",
       "      <td>5811.0</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>279500.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>202421.064584</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  median_sale_price  median_list_price  median_ppsf  \\\n",
       "0  2012-03-31            46550.0           217450.0    31.813674   \n",
       "1  2012-04-30            61870.0           245000.0    40.723982   \n",
       "\n",
       "   median_list_ppsf  homes_sold  pending_sales  new_listings  inventory  \\\n",
       "0        110.183666        14.0           23.0          44.0       64.0   \n",
       "1        130.528256        22.0           29.0          56.0       69.0   \n",
       "\n",
       "   median_dom  avg_sale_to_list  sold_above_list  off_market_in_two_weeks  \\\n",
       "0        59.5          0.943662         0.142857                 0.043478   \n",
       "1        89.5          0.946642         0.090909                 0.034483   \n",
       "\n",
       "  city  zipcode  year  bank  bus  hospital  mall  park  restaurant  school  \\\n",
       "0  ATL    30002  2012  12.0  2.0       4.0   1.0  60.0        45.0    57.0   \n",
       "1  ATL    30002  2012  12.0  2.0       4.0   1.0  60.0        45.0    57.0   \n",
       "\n",
       "   station  supermarket  Total Population  Median Age  Per Capita Income  \\\n",
       "0      4.0          7.0            5811.0        36.3            33052.0   \n",
       "1      4.0          7.0            5811.0        36.3            33052.0   \n",
       "\n",
       "   Total Families Below Poverty  Total Housing Units  Median Rent  \\\n",
       "0                        5811.0               2677.0        710.0   \n",
       "1                        5811.0               2677.0        710.0   \n",
       "\n",
       "   Median Home Value  Total Labor Force  Unemployed Population  \\\n",
       "0           279500.0             3171.0                  460.0   \n",
       "1           279500.0             3171.0                  460.0   \n",
       "\n",
       "   Total School Age Population  Total School Enrollment  Median Commute Time  \\\n",
       "0                       5408.0                   5408.0               2492.0   \n",
       "1                       5408.0                   5408.0               2492.0   \n",
       "\n",
       "           price                         city_full  \n",
       "0  200773.999557  Atlanta-Sandy Springs-Alpharetta  \n",
       "1  202421.064584  Atlanta-Sandy Springs-Alpharetta  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "['date', 'median_sale_price', 'median_list_price', 'median_ppsf', 'median_list_ppsf', 'homes_sold', 'pending_sales', 'new_listings', 'inventory', 'median_dom', 'avg_sale_to_list', 'sold_above_list', 'off_market_in_two_weeks', 'city', 'zipcode', 'year', 'bank', 'bus', 'hospital', 'mall', 'park', 'restaurant', 'school', 'station', 'supermarket', 'Total Population', 'Median Age', 'Per Capita Income', 'Total Families Below Poverty', 'Total Housing Units', 'Median Rent', 'Median Home Value', 'Total Labor Force', 'Unemployed Population', 'Total School Age Population', 'Total School Enrollment', 'Median Commute Time', 'price', 'city_full']\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(\"Columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Year from Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year range: 2012 to 2023\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime and extract year\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Check year range\n",
    "print(f\"Year range: {df['year'].min()} to {df['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows per year:\n",
      "year\n",
      "2012    62260\n",
      "2013    74712\n",
      "2014    74712\n",
      "2015    74712\n",
      "2016    74712\n",
      "2017    74712\n",
      "2018    74712\n",
      "2019    74712\n",
      "2020    74712\n",
      "2021    74712\n",
      "2022    74712\n",
      "2023    74712\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Year distribution\n",
    "print(\"\\nRows per year:\")\n",
    "print(df['year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temporal Split (by Date)\n",
    "\n",
    "We split by date instead of randomly to prevent data leakage:\n",
    "- **Training**: 2012-2019\n",
    "- **Evaluation**: 2020-2021  \n",
    "- **Hold-out**: 2022-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TEMPORAL DATA SPLIT SUMMARY\n",
      "==================================================\n",
      "Training set (2012-2019):   585,244 rows\n",
      "Evaluation set (2020-2021): 149,424 rows\n",
      "Hold-out set (2022-2023):   149,424 rows\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Define cutoff years\n",
    "EVAL_CUTOFF = 2020\n",
    "HOLDOUT_CUTOFF = 2022\n",
    "\n",
    "# Split the data\n",
    "train_df = df[df['year'] < EVAL_CUTOFF].copy()\n",
    "eval_df = df[(df['year'] >= EVAL_CUTOFF) & (df['year'] < HOLDOUT_CUTOFF)].copy()\n",
    "holdout_df = df[df['year'] >= HOLDOUT_CUTOFF].copy()\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"TEMPORAL DATA SPLIT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training set (2012-2019):   {len(train_df):,} rows\")\n",
    "print(f\"Evaluation set (2020-2021): {len(eval_df):,} rows\")\n",
    "print(f\"Hold-out set (2022-2023):   {len(holdout_df):,} rows\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training years: 2012 - 2019\n",
      "Evaluation years: 2020 - 2021\n",
      "Hold-out years: 2022 - 2023\n"
     ]
    }
   ],
   "source": [
    "# Verify year ranges\n",
    "print(f\"Training years: {train_df['year'].min()} - {train_df['year'].max()}\")\n",
    "print(f\"Evaluation years: {eval_df['year'].min()} - {eval_df['year'].max()}\")\n",
    "print(f\"Hold-out years: {holdout_df['year'].min()} - {holdout_df['year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved datasets:\n",
      "  - ..\\data\\raw\\train.csv\n",
      "  - ..\\data\\raw\\eval.csv\n",
      "  - ..\\data\\raw\\holdout.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "train_df.to_csv(DATA_DIR / \"train.csv\", index=False)\n",
    "eval_df.to_csv(DATA_DIR / \"eval.csv\", index=False)\n",
    "holdout_df.to_csv(DATA_DIR / \"holdout.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved datasets:\")\n",
    "print(f\"  - {DATA_DIR / 'train.csv'}\")\n",
    "print(f\"  - {DATA_DIR / 'eval.csv'}\")\n",
    "print(f\"  - {DATA_DIR / 'holdout.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data splitting complete! Proceed to notebook 01 for EDA and cleaning.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✅ Data splitting complete! Proceed to notebook 01 for EDA and cleaning.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
